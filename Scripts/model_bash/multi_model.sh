CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 PEFT_SHARE_BASE_WEIGHTS=true python3 -m fastchat.serve.multi_model_worker \
    --port 31022 --worker http://localhost:31022 \
    --host localhost \
    --model-path /data/rolnan/FastChat/lora/hotpotqa/13b-from_70_150-hotpotqa-plan-5-epoch \
    --model-names "13b_from_70b_150_plan_peft" \
    --model-path /data/rolnan/FastChat/lora/hotpotqa/13b-from_70_150-hotpotqa-action-5-epoch\
    --model-names "13b_from_70b_150_action_peft" \
    --model-path /data/rolnan/FastChat/lora/hotpotqa/13b-from_70_150-hotpotqa-reflect-5-epoch \
    --model-names "13b_from_70b_150_reflect_peft" \
    --max-gpu-memory 31Gib \
    --dtype float16 \
    --num-gpus 8